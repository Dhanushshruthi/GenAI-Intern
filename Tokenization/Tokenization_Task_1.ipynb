{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "WORD TOKENIZER\n"
      ],
      "metadata": {
        "id": "PL26bjSYh_is"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7hbSCr3N_mP",
        "outputId": "7af96f59-89df-418c-df78-7c582290dc86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review  \\\n",
            "0  One of the other reviewers has mentioned that ...   \n",
            "1  A wonderful little production. <br /><br />The...   \n",
            "2  I thought this was a wonderful way to spend ti...   \n",
            "3  Basically there's a family where a little boy ...   \n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
            "\n",
            "                                    tokenized_review  \n",
            "0  [One, of, the, other, reviewers, has, mentione...  \n",
            "1  [A, wonderful, little, production, ., <, br, /...  \n",
            "2  [I, thought, this, was, a, wonderful, way, to,...  \n",
            "3  [Basically, there, 's, a, family, where, a, li...  \n",
            "4  [Petter, Mattei, 's, ``, Love, in, the, Time, ...  \n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure nltk resources are available\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "def load_and_tokenize(file_path, tokenize_by='word'):\n",
        "    \"\"\"\n",
        "    Load a dataset and tokenize the text data based on the specified type.\n",
        "\n",
        "    Parameters:\n",
        "    file_path (str): Path to the CSV file containing the data.\n",
        "    tokenize_by (str): Tokenization type ('word' or 'sentence'). Default is 'word'.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: DataFrame with an additional column of tokenized text.\n",
        "    \"\"\"\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    # Check if 'review' column exists\n",
        "    if 'review' not in data.columns:\n",
        "        raise ValueError(\"The dataset must contain a 'review' column.\")\n",
        "\n",
        "    # Tokenization function based on type\n",
        "    if tokenize_by == 'word':\n",
        "        data['tokenized_review'] = data['review'].apply(word_tokenize)\n",
        "    elif tokenize_by == 'sentence':\n",
        "        data['tokenized_review'] = data['review'].apply(sent_tokenize)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid tokenize_by value. Use 'word' or 'sentence'.\")\n",
        "\n",
        "    return data\n",
        "\n",
        "# Example usage\n",
        "file_path = '/content/drive/MyDrive/IMDB Dataset.csv'  # Replace with the actual file path\n",
        "tokenize_by = 'word'  # Change to 'sentence' for sentence tokenization\n",
        "data = load_and_tokenize(file_path, tokenize_by)\n",
        "\n",
        "# Display the first few tokenized reviews\n",
        "print(data[['review', 'tokenized_review']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SENTENCE TOKENIZER"
      ],
      "metadata": {
        "id": "3UatD1cWSmd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure nltk resources are available\n",
        "nltk.download('punkt')\n",
        "\n",
        "def load_and_sentence_tokenize(file_path):\n",
        "    \"\"\"\n",
        "    Load a dataset and perform sentence tokenization on the text data.\n",
        "\n",
        "    Parameters:\n",
        "    file_path (str): Path to the CSV file containing the data.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: DataFrame with an additional column of sentence-tokenized text.\n",
        "    \"\"\"\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    # Check if 'review' column exists\n",
        "    if 'review' not in data.columns:\n",
        "        raise ValueError(\"The dataset must contain a 'review' column.\")\n",
        "\n",
        "    # Perform sentence tokenization\n",
        "    data['sentence_tokenized_review'] = data['review'].apply(sent_tokenize)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Example usage\n",
        "file_path = '/content/drive/MyDrive/IMDB Dataset.csv'  # Replace with the actual file path\n",
        "data = load_and_sentence_tokenize(file_path)\n",
        "\n",
        "# Display the first few sentence-tokenized reviews\n",
        "print(data[['review', 'sentence_tokenized_review']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df3j7z_KSDL4",
        "outputId": "10c5c387-bcd3-4d2a-8559-75257a1bf054"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review  \\\n",
            "0  One of the other reviewers has mentioned that ...   \n",
            "1  A wonderful little production. <br /><br />The...   \n",
            "2  I thought this was a wonderful way to spend ti...   \n",
            "3  Basically there's a family where a little boy ...   \n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
            "\n",
            "                           sentence_tokenized_review  \n",
            "0  [One of the other reviewers has mentioned that...  \n",
            "1  [A wonderful little production., <br /><br />T...  \n",
            "2  [I thought this was a wonderful way to spend t...  \n",
            "3  [Basically there's a family where a little boy...  \n",
            "4  [Petter Mattei's \"Love in the Time of Money\" i...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6zWneD5B5ML",
        "outputId": "68689a53-1e56-4c20-a052-d136209f4faa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o-6b1MMmQmrb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}